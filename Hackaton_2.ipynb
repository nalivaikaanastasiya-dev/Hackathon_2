{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalivaikaanastasiya-dev/Hackathon_2/blob/main/Hackaton_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn75-53gRTmb"
      },
      "source": [
        "# **Fine-Tuned LLM for Sentiment Analysis and Contextual Responses**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRmkZdPVSJgw"
      },
      "source": [
        "# **Step 1: Define the Goal & Dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DLryGU1FRfNY"
      },
      "source": [
        "**Goal:**\n",
        "\n",
        "\n",
        "*   Classify the sentiment of user text (positive / negative).\n",
        "*   Generate a context-aware response based on both user input and retrieved external information.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0acBXPsRRuEK"
      },
      "source": [
        "**Domain Choice:**\n",
        "Movie reviews"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv2eBKHBR3-Y"
      },
      "source": [
        "**Dataset:**\n",
        "\n",
        "\n",
        "*   IMDB Movie Reviews Dataset\n",
        "*   Binary sentiment labels: positive, negative\n",
        "*   Subsample: 10,000 examples to keep training lightweight.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"imdb\")\n",
        "\n",
        "dataset[\"train\"] = dataset[\"train\"].shuffle(seed=42).select(range(10000))\n",
        "dataset[\"test\"] = dataset[\"test\"].shuffle(seed=42).select(range(2000))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345,
          "referenced_widgets": [
            "cff585544384414683c8525f3bd78a12",
            "4efab527ee55485c8de8738fb9d0ec0c",
            "63ab14e01b5c473fa9fb762ac4c8b9e2",
            "7aac9039184e45a190eb33815985c7fc",
            "894e05f913ad4913b540449bfb587c0c",
            "7fa8f04b0e9245238409aa50a4296520",
            "de59d5945bf74d7eba5f438e6ac5c428",
            "69cdcc08bdce425697ab87520855474d",
            "ba80ce10d06b4579877892e475d9a624",
            "2554e0b1b8ee454db4608f35330d3464",
            "6bc8a464eac74dd59d5a4c71cda60e2c",
            "4a0248f0f205439588e501222fe421fb",
            "ae216da4156a4c8bba26d4a3a7d32018",
            "4552ba0a1b424e049921b6587eaae1c2",
            "77b400642bd24c28b503217e45a3c775",
            "9838821388814297bb916efffa00a782",
            "ab44267555a742dca072722d506b0f01",
            "bd81471206274e1b829c69b304537946",
            "3e53038269fe4d929912da0af9c993bf",
            "b6816cd68c3143c0aba3107dd65af3c2",
            "7d521459b9064cd7b39d5953bdcd84a6",
            "950b0ed587de4e67bfbfcddcf020f8f8",
            "251fc341d18e4bc38ffc73366d61af78",
            "d667271ecf24458f985a0a34832cc9fe",
            "6fbb90e638e5471c964fbb9cb4037cba",
            "edf36c6a1ea049158535945beefd2804",
            "3a60e38a7c394245b332e2a68c4b45fa",
            "85b4ebeaf48d4ee2acc7828bc0e38561",
            "275c10674ab7458e8e84e48085916fee",
            "86c44401331f442eb967668c17007efb",
            "b62c33405d814f0784636231faf8890b",
            "29c662847ab049ab83384878535907e8",
            "587ac236bb5046069757a3dadb8a35f9",
            "d16ab2d614084d1aae8e8e35874c8805",
            "fa0cab7a5f9f41f58085948377f027c4",
            "677240a88b474135a5ddaf1170d55f11",
            "32a546955dc848f79d65ddb506a0d1d7",
            "71ca09b8b61d42d5b7efd5c58103813e",
            "067de06c333a4a73b9417e65a748de6f",
            "597f7d0d5d5940f29518286729a8cfd6",
            "8b05e14cc8e14eb186a1e71a372e1bb4",
            "f704a03481da46449b74c7117e3d64ea",
            "fe8b6af4730b4440801c739231d3b9cb",
            "e90d4573f450418c8f3538666cf3fd27",
            "cf704463280e45c486acc025a46838ba",
            "713a4cba76a447d5820f259765ba15bc",
            "5cb557bf1dfc42a39d40d09700c32624",
            "053ba0876de3416e8d93d973bb734192",
            "020144fe51204e97abff20e976a11de1",
            "aca639738d164362a5e1cff3c507fea0",
            "eb4e2565d6394897aafc67d6f9bb1a4f",
            "6f520f60035640b28044936ced35ba9b",
            "3a1a3e967e1242c082cf31ce25a733c4",
            "305c39d43e434277b733eea6d8356bb4",
            "73bd46e406f2474189ee77a6b24dd3cd",
            "cd6975c5358f49d6a40d6243c72e16e3",
            "cf65b274bc604589a23c083c43e75c12",
            "127454eb878444fc8d6f255ef7f99003",
            "23daf0cea5d84157a7635132a00f8535",
            "36cb61defe3a4408b6ee6858f5ccc0de",
            "27037f212a4c43ec9f6419a83601c49f",
            "4e5046094f7e48cf9c0c9f1a27782116",
            "f835edd3b6a2407b84aab6e7994b0414",
            "d0903049d33a4a0a9d26be45abdfba33",
            "991e0443ffc9465bb9f9db9d99f69f35",
            "44b71f9cee9c490d919bc51ca8dbeb5a",
            "1e457de751da43888ad44f7f9f8db067",
            "61ff7328c4b343ee90356484d7e7a452",
            "760050a343b042a38da0dce5af33ed8c",
            "33d3c4aead294a279dc1bd397e25a87d",
            "c1e7fdf3bf4b4cc5939edf85dda4d332",
            "68a23f77cf084c19b24c8c8d0977e7a7",
            "c17e231156ff4106928bbbcca137b5e4",
            "6e2b5cc06c9f4c11b0c7d976163753f1",
            "73ef1dd31bbe4fd5866040158c41df22",
            "3b8ddb54c2d84716b807afe95b79c659",
            "bfde2f2fc20a4408bccf84a3029b8e02"
          ]
        },
        "id": "UUaW04-JIvJR",
        "outputId": "b43dd852-a82b-4c2f-e060-7b94d0d6e921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cff585544384414683c8525f3bd78a12"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/train-00000-of-00001.parquet:   0%|          | 0.00/21.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a0248f0f205439588e501222fe421fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/test-00000-of-00001.parquet:   0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "251fc341d18e4bc38ffc73366d61af78"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "plain_text/unsupervised-00000-of-00001.p(…):   0%|          | 0.00/42.0M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d16ab2d614084d1aae8e8e35874c8805"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf704463280e45c486acc025a46838ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/25000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd6975c5358f49d6a40d6243c72e16e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unsupervised split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1e457de751da43888ad44f7f9f8db067"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNf_Q3nqTK65"
      },
      "source": [
        "# **Step 2: Choose a Base Model & Load Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wJ9pWUDVTNz3"
      },
      "source": [
        "**Base Model:**\n",
        "distilbert-base-uncased\n",
        "\n",
        "\n",
        "*   Lightweight\n",
        "*   Fast on CPU\n",
        "*   Good performance for classification\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHMzFykgTjb1"
      },
      "source": [
        "**Tokenization**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "d59c472f594642a49c0a17a5f6e047e9",
            "4ac0ff7e91184adfa7a0968d25fca3fe",
            "5b7a8bdf3dc44c2693c417652b09cb4c",
            "17b8a10919844e08b39eb712d3ad0709",
            "85443447737045e3945bee9fd0972e5f",
            "affd635276fb4aa181d67324c3d56661",
            "238bc756cd21431aac40e94a9a5cc82d",
            "32001a9384b4408bb08cbd641344cdfb",
            "4745d9cbd0b8436f852d77e732513eaf",
            "b7bbfc120afa4841a3d77e76ed11201b",
            "9bc1931d09954e0db6fb4396bd53f96a",
            "9f9e0b36326c477fbb9702b8e8313d0c",
            "a61e50b54e53423dab1c51ce2bf2f21e",
            "30817a68d6774464983110e905505376",
            "2f72db30bd504b8d80b350baab6ec8d7",
            "5bde1be0b2544ee28cfb7cdef8750662",
            "219a592e0a484d30bdecd11021aeaaf8",
            "11ecbf400e464e0b8ebee9545b70b9df",
            "0823cdf2a90f451da4d9e116db5558ae",
            "05df9d859d1740adbcc68dc7d98a3774",
            "6eb1fb1cb4874f11b9c9ef6c91ec0b7f",
            "2d9f0ce35bb3470c9a98e62ac723432e",
            "1d7e5d8de63a4f8baa376a95d6376080",
            "7fe8379f783c4899aa47ebdb1fec4e1a",
            "252bd0f99e8f476583a12f8ccf95e4a6",
            "2f6c580b17284df49ea9ed2c19022351",
            "1b735339bc544bdeb9093782ff306f33",
            "634fafdab6d34ba3a1a9b10e8182c035",
            "e696822e5fe94d45b0feeaa197f8fe46",
            "3410e6294f134f63a59283430a2a48b9",
            "57cb2c6c8ac243dc85e6a118c90c6d5b",
            "0e8a06dcdafa4ad0b9f88715454ed168",
            "5cb2588946bb4a04b8ca7975caae22a4",
            "efe3ff07ffdd43a282302338eb664110",
            "109ee4bb28bf440bb72a95734f5708c9",
            "16ac7f014aa04a70915887f71c34cfbf",
            "435b5947e7424f7cb65f3bcf39fdae4b",
            "b31281a24dfd40d3a26d3785d1597d3c",
            "c15e2389627b4fc58119f87372b4907c",
            "548cb5eb59024024a6f59ac69fb8ac7b",
            "3fc36bec79fd45f5996cc948217792c6",
            "f391e3a59ef5412ea2156e79492c3b09",
            "c7e2cad1bc4843498fa18eaa0d15b739",
            "fbf67ef773e349578c906f17157cb2bc",
            "2d5fe7fcf65c4b20b7e6ff8ef201d687",
            "7a2ab05c5e5e4d3081dcb77f538e64be",
            "5d1ca3002f22469ba2225338c54f9260",
            "66fff48300b346d1bf8f79ec3092c843",
            "45f154f414e24548ae6b9de3a020e51e",
            "abe16c0a738b40dabbe12917d1f9c36c",
            "6e0450a85e1f449994bd1e5e6d2d8e31",
            "1e976f4780964d91a117a88795be82e9",
            "d8339134229847999b2e61e25149015e",
            "7c8e8d6883ca44729ff2bc34a1175f68",
            "ddeab1e2e44b414db17acf17af573abb",
            "92264d0446d0415eb7e9c5823642c6e9",
            "c7cf502bee7448aca9e51a51ef5eb5b5",
            "27517e9667464452be0f4ee51ce4c5e8",
            "254d4a123d3548eaa33296cbe4af7ab0",
            "dd7a7dd594404f7697aa989d707a6ec5",
            "aa9062815cab47a88e7f086e5be175e4",
            "fcedfa67ebe74923ad403a7593088d4c",
            "6fa355b10e414fc9ae4814e62880000a",
            "eab6f76167a043bdae203554b76fa61a",
            "5cf0f92e2c78467bb3d0f29c1679136e",
            "b7e7241e4e824a8ca9feeebeef53b10c",
            "a64d24af9de34440b8f1ec58794fafbf",
            "3c5687ad199c49ce8c058fb330eb6f64",
            "16a49757996b4733909176d108048065",
            "04a443c45403481488b80acbe27625e2",
            "902aedbe461e463697b40d2ffdbd22b6",
            "f78fd769d364457f87b531cdb7568c57",
            "10855fd158c64c908d68713551edaac9",
            "493ed40e19dd45258ff0ed0880b293a9",
            "0f8781d68b0a486894367259c30e1231",
            "d45219c7f30843bc91745e2495b57bff",
            "420b5d6fb28c4881b4b45dd970b8e6a4"
          ]
        },
        "id": "CkvrIHqcTk_Q",
        "outputId": "47dda39d-9b08-4e63-baff-1e485e177872"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d59c472f594642a49c0a17a5f6e047e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9f9e0b36326c477fbb9702b8e8313d0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d7e5d8de63a4f8baa376a95d6376080"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "efe3ff07ffdd43a282302338eb664110"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/10000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2d5fe7fcf65c4b20b7e6ff8ef201d687"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/2000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "92264d0446d0415eb7e9c5823642c6e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a64d24af9de34440b8f1ec58794fafbf"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "def tokenize(batch):\n",
        "    return tokenizer(batch[\"text\"], truncation=True, padding=\"max_length\", max_length=256)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize, batched=True)\n",
        "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
        "tokenized_dataset.set_format(\"torch\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccgkrFtlUNDg"
      },
      "source": [
        "# **Step 3: Parameter-Efficient Fine-Tuning with LoRA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDh-3un4UP6k"
      },
      "source": [
        "**Why LoRA?**\n",
        "\n",
        "\n",
        "*   Only trains small low-rank matrices\n",
        "*   Freezes base model weights\n",
        "*   Memory-efficient and fast\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GywrnJv2UeEw"
      },
      "source": [
        "**LoRA Configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3fZ1aAWJUfh7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "da7c159d3f6b4c6987bd8fa9a51a3798",
            "a5471da2ccec4db186e2ce00f78793dd",
            "da6552aa3b174d30a71f4cd826573a3f",
            "edab0a41634d4259a2d43d61360ec9ea",
            "7218c538af2e4556a188acc321b9150b",
            "5d067cc5b2754c46bb2c3dcb58551d4d",
            "e06fb1e95c6d468bbb491244da0e2c34",
            "a2bab80b5d304badad7af1813736f99c",
            "5133388527d14f9b8e04f1e2ddc4bfc7",
            "696178a54abd4c7f9940b5f22350b4e0",
            "ecd9d500d6b644468922134f88a47393"
          ]
        },
        "outputId": "0bb860a2-229d-4cdb-fea5-93f7a99040e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "da7c159d3f6b4c6987bd8fa9a51a3798"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 739,586 || all params: 67,694,596 || trainable%: 1.0925\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"distilbert-base-uncased\",\n",
        "    num_labels=2\n",
        ")\n",
        "\n",
        "lora_config = LoraConfig(\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    target_modules=[\"q_lin\", \"v_lin\"],\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    task_type=\"SEQ_CLS\"\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, lora_config)\n",
        "model.print_trainable_parameters()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w8_R8LPUUube"
      },
      "source": [
        "# **Step 4: Train & Validate the Classifier**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Me-7_ptQU4Jm"
      },
      "source": [
        "**Training Setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2npmsjuLWAI0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "outputId": "09692b4e-26e4-4f0a-f6cd-581a73797185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py:668: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
            "  warnings.warn(warn_msg)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1250' max='1250' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1250/1250 2:50:18, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.328800</td>\n",
              "      <td>0.296342</td>\n",
              "      <td>0.881500</td>\n",
              "      <td>0.879602</td>\n",
              "      <td>0.884000</td>\n",
              "      <td>0.881796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1250, training_loss=0.35686854858398437, metrics={'train_runtime': 10226.5735, 'train_samples_per_second': 0.978, 'train_steps_per_second': 0.122, 'total_flos': 673697034240000.0, 'train_loss': 0.35686854858398437, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels, preds, average=\"binary\"\n",
        "    )\n",
        "    acc = accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": precision,\n",
        "        \"recall\": recall,\n",
        "        \"f1\": f1\n",
        "    }\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    learning_rate=1e-4,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=1,\n",
        "    fp16=torch.cuda.is_available(),\n",
        "    logging_dir=\"./logs\",\n",
        "    save_strategy=\"epoch\",\n",
        "    report_to=\"none\"\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_dataset[\"train\"],\n",
        "    eval_dataset=tokenized_dataset[\"test\"],\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gt8K8MG4Wla9"
      },
      "source": [
        "**Metrics:**\n",
        "\n",
        "*   Accuracy\n",
        "*   Validation loss\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q26kj6S3W8LP"
      },
      "source": [
        "# **Step 5: Build a Retrieval Component**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TGXRM74fXBKM"
      },
      "source": [
        "**Embeddings Model**\n",
        "\n",
        "sentence-transformers/all-MiniLM-L6-v2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "dv7PKpdqYsMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8dc771c2-85be-415c-8450-fdf32d259520"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.2.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Requirement already satisfied: transformers<6.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.57.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.9.0+cpu)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.36.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.20.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.6.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (2025.11.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<6.0.0,>=4.41.0->sentence-transformers) (0.7.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.11.12)\n",
            "Downloading faiss_cpu-1.13.2-cp310-abi3-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (23.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.8/23.8 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.13.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m5hfsIelXM6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418,
          "referenced_widgets": [
            "2fa23977d43748cf92e71da880773cee",
            "6400020ead9d458fb5a0b79afa1e766d",
            "c9b2fc255e21471098c820209a3becad",
            "54d6ba6fefb84ed1a0458fc35401e1c3",
            "de070a6f6add468abc523e75c05cc4b3",
            "4233c046d60c4cf1acfd7e12f6fac55d",
            "73f023c571a34536b38d1d2d9dfe2fe5",
            "376ff79a85174f52b7c7b00ddd777109",
            "df4239c05343426e9753865db417e870",
            "2499de7ee0f54184b0e2a4cf37dff8bf",
            "f587b14f6e004df6b57ff1380218f94a",
            "c22740d2031d4f188ae31698ebeedbdc",
            "f2ccec6cb89f4c929241a11d39c72515",
            "4fe4acdfc7904a3c8cad6a199c406c80",
            "fe50458c6c9d47b4ba1f0c01c3c58823",
            "43b6e6d546bd4e559390c3b8401159d2",
            "b8af4cce9602494c88ebfafd6d401bc4",
            "35db010447284ef9aa6495b04f2e9fff",
            "c2af351bc574429cb8d0ccc636838ecf",
            "dc4324ea42494891b96147920843e05c",
            "1e4b0be1df1b486b89231c56fc252e17",
            "74f338cc4e8a43f490a751a024668ef0",
            "ca6ebe0db2a94851857b0f65426b7ad7",
            "751681e823e14359b9dd3c273d4827e1",
            "316acdf29f7e44d0a878386ddcb1b8ef",
            "a6922769d5264621a8734474bc768c67",
            "22538460ae884e27968c0ebdd113fb47",
            "3d8b1898e568457db2cfd201fc037d72",
            "179490e9602b4485ae62d93fb1a1d67a",
            "118c80b577bf484bae5202bcbd097cc7",
            "332799204e8d4316829e79f785355d15",
            "1950a3de277343df9baab17a66f7274c",
            "acd640ca0a344655807c5a79cc7be9be",
            "9cb920c05bdc46cd9d326bf016e699a6",
            "b9fe1cab67194a81b8639442160a7b48",
            "694f4af80ca44ec39513c0c18703d30f",
            "c59efc62d1b34e6884d59e2a3161a69d",
            "c200ac5269c4458c93f7e12a51dda07b",
            "1349db81b92f416ca119e175fe7acb5c",
            "df687e58acd04d1a941ba0cc5201d383",
            "785806268fa54a33b3e7baf6339a44e3",
            "6187c75e45d94c0a97429b02040366e3",
            "0ef8a8e73c3c453eb46226921af92d97",
            "94b06cdc5d614713be5021cfe54c2a2b",
            "40bee3e0bb7046a2a71527710e840dd9",
            "1f419fc9a9da43ceb4c12945afd1d461",
            "20feabf84b7248d5b35bec44afb0eabe",
            "435607c316794ba887ae47c06d5412f9",
            "faa1ab3bd48d4816894bfdbc999ea023",
            "23577d6d70e14f978a9a660cd0c00b00",
            "0d820d8b41c441f4a14a1a8a937c0521",
            "86c6622fa09e420e994c9ffe6ff51133",
            "3f15c0e834e64920b3e01eefa525d470",
            "716c9934c8be419b842b09ab6bced7c2",
            "6d766d32d58c4e0db75f53bf6425fd4b",
            "661d9081df794f4a845ee335862622c7",
            "ca2ed6dff31a45b8bdb65cc601be72aa",
            "29fc1fbe748540c097a6ffcb8fc91d96",
            "2d1c4257488640b4b49be93f98e23808",
            "4df1cabbcf46468e9cebdbdfb17cb240",
            "a00155a671d443ac9f85f37fd82be45d",
            "fbf7e85d1fce4afab8a6c3f89fd9d19d",
            "f9574421b5d14053883c7fc160106895",
            "af527b040d5c4cacbd67ca88d157626b",
            "83a52523311a4838a10e2a9a1b367b48",
            "ef7742cf70944fc5a90efee75ea8bb4c",
            "2551e2acc53a4de98ab181093760351a",
            "ebb32d493e3946f89362a0d724d62c49",
            "658365fbddb74308841e14325782d27c",
            "58b865d3212640f08c043625e95600c7",
            "b470df6ee0724eb7a62b5d970b289c14",
            "c1a1f60492104716b00e0fd0fb621138",
            "9164615e1fc648ddbc0544f68793b81c",
            "4bade9411a734f40ad42d4d876a3c429",
            "321caa6696814b159e671e6261bdfbe2",
            "959c2163842e45b892f2b1949c6974bf",
            "22f2bc2eab324b4bbc2b04f707c3bbad",
            "0aae187471f1456db44cdc2b96d19e75",
            "71cd1ae001824469b87305d489cf0b83",
            "9c357974bf7f4d0f9e4f5e6735fda75b",
            "81b5b1566cb140f0bc6adb6f99f8156c",
            "4171a7ef59c3492d9e67c13729c12305",
            "9f74acc5b10e468b9da6d5a76f50af2b",
            "8cc2ee0cf6d64ffcbab723e073b85a86",
            "f071b476b9554c03b7adb4d044184643",
            "62e39163ada24f20b5c6ebbb42d1d1dd",
            "cfb861b1566c422b83a99b2b5733fdec",
            "bc3a368f94e043589273c041b37ec62d",
            "ee6c43fe23ed4937a082875e7ec42ff3",
            "d4c8d96317884b8f8b52c570485d6865",
            "c6fe4f6f3fb74972907de584261d5d64",
            "a82836e875474bf7b036dc9707ced560",
            "4ea498fb2e694c51b9a1a3e3cfaa86b9",
            "070c4e7bdf4a4732aa8e28337e513781",
            "9e89f0bc48584590adf7675dca0e1a62",
            "8e1f355754c54c1cad61d58047cd2b76",
            "88aed85ff7a748718fda746221ac476b",
            "8409e60d5a914d19b4075876181178dd",
            "d39c9afe88af451696e888cf4cb08e67",
            "110d12de09fc4c5a91bb27772a478f10",
            "e39661015e9c42d3a3ca630a7c65e6c0",
            "f08a387a4c054fe295c37f220c04703e",
            "0bd8dc806d08458393bbb2850d59325c",
            "99c4212ebe45430e8ba82796ba66538d",
            "94b332b296654cddbb85feafa858b7f0",
            "3b53ef48191f473cbf841ca154565883",
            "b71bd1bd5f7c4b3a927c6622f6271a20",
            "ab98972bb7594c55b080b37be89c7587",
            "54155c745a994299b634e6ff75eab459",
            "606ccebf529f44ebaaedc0d1e6e59afd",
            "6f4f2ef291154572915c31eab0a79b4b",
            "cae1f59ca30548bfb31cd27afb8e7cbb",
            "70f5a048e2b1483c9e9916e732205e2f",
            "6deec256550548c2a662d5dcf6f8255b",
            "8a21fb90ff8a4b7ca443fc566c32b52e",
            "be36c715f7bf4d2ab3428fd7649c55e4",
            "4f0f15d289f74318b6ebe73aac9297d9",
            "2df19d424baf4aff83874a1aaaad35bc",
            "7be4ec3d0a1b4f158089b61fd436e018",
            "17fcfa5e007b494bab610bf3a45ff973",
            "6e9f2a6b99a946148b15d10488d101e0",
            "4b77f68357784791b753e41b5280abb2",
            "072ac805b4ac4a60b1a2ce95fe516fb1",
            "89a47011bf864746b8547ee66aaffd5f",
            "421d738271f343d69c635c75ed294af4",
            "dec2f330a19b43f4a34fa92d1233a17f",
            "efe158d6a4b44cda9a5725da8388636a",
            "5cfde912909540f3a68b0f32d53ae41c",
            "32397b4767034567a4b94f28be6b7a42",
            "3311e386e1034204bca7f9e4f496876d",
            "5b7282c3d2954e34854645a93d36e3de",
            "4e362d9ee48f46fa8a452bbc2c33cc1d"
          ]
        },
        "outputId": "8ff85337-b662-42a3-c42b-e4409b42a0e0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2fa23977d43748cf92e71da880773cee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c22740d2031d4f188ae31698ebeedbdc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ca6ebe0db2a94851857b0f65426b7ad7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9cb920c05bdc46cd9d326bf016e699a6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "40bee3e0bb7046a2a71527710e840dd9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "661d9081df794f4a845ee335862622c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2551e2acc53a4de98ab181093760351a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0aae187471f1456db44cdc2b96d19e75"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ee6c43fe23ed4937a082875e7ec42ff3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "110d12de09fc4c5a91bb27772a478f10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6f4f2ef291154572915c31eab0a79b4b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Batches:   0%|          | 0/125 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b77f68357784791b753e41b5280abb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FAISS index size: 2000\n"
          ]
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "import numpy as np\n",
        "\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "corpus = dataset[\"train\"][\"text\"][:2000]\n",
        "\n",
        "embeddings = embedder.encode(\n",
        "    corpus,\n",
        "    batch_size=16,\n",
        "    show_progress_bar=True,\n",
        "    convert_to_numpy=True\n",
        ")\n",
        "\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "print(\"FAISS index size:\", index.ntotal)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dmZRqCyYXJU7"
      },
      "source": [
        "**Retrieval Function**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dID7GsKZXUEo"
      },
      "outputs": [],
      "source": [
        "def retrieve_context(query, k=3):\n",
        "    q_emb = embedder.encode([query])\n",
        "    distances, indices = index.search(q_emb, k)\n",
        "    return [corpus[i] for i in indices[0]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqB3eO0MXW1G"
      },
      "source": [
        "# **Step 6: Generate Context-Aware Responses**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f-eOq-6-XcsL"
      },
      "source": [
        "**Prompt Construction**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fh9B_BVQXfrw"
      },
      "outputs": [],
      "source": [
        "def build_prompt(user_input, context, sentiment):\n",
        "    context_text = \"\\n\".join(context)\n",
        "    return f\"\"\"\n",
        "User input: {user_input}\n",
        "Detected sentiment: {sentiment}\n",
        "\n",
        "Relevant context:\n",
        "{context_text}\n",
        "\n",
        "Generate a helpful and empathetic response.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysPXztdbXnBB"
      },
      "source": [
        "**Response Generation**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "user_input = \"The movie was boring and too long\"\n",
        "sentiment = \"negative\"\n",
        "context = [\"Example context sentence 1\", \"Example context sentence 2\"]\n",
        "\n",
        "prompt = build_prompt(user_input, context, sentiment)"
      ],
      "metadata": {
        "id": "F_RI4AFJfUvb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8fkXkRPXoct",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415,
          "referenced_widgets": [
            "a64f82db014a4369b67ba7ea9e87d892",
            "205e32b939e04b74b6f8cf93be970d1c",
            "8ac5f74968534c1e9afd6a751fc2b12c",
            "84e914ec62694cf28a691a1bf22d9a46",
            "b9691a5038c14e9bb5f52a6a057f60b0",
            "48f46f2072c0452d8be11fdd18c067fd",
            "570a37b9694d48e89f34692f79837813",
            "682e8a18403046689e14cff05bf600b5",
            "56bbbf8e52be4b8a8c664485a041571e",
            "f702884a48b04028bb43c9d0b96a2191",
            "85a759bdf76040a4af78eb5c02a0ec80",
            "f95de66bd52b4fb980de0a6260af1d0a",
            "485884114ba8449dad8a08d51cf023dd",
            "1b1cf2f13e1346ff89d0e659e7326cfd",
            "9eb144744d4d42da83b6f90b07007f13",
            "74d25a50f3624c2faef468211d5d089f",
            "ef94d2fdae154587ba5aca21b6f33f22",
            "fd2bc817446d4aa5b9e7690d4ba3d8dd",
            "bb924db23cc74e6ca5dc4c5f897ab440",
            "44c76e2b67364a069b0b8f6cfb263aaf",
            "d8e078529ebb4b0da63a387468bd6754",
            "218cca2a6f384445930f7ad7803d4f39",
            "8ca451f439f94b97a05ee10da51b5147",
            "c55f2dc5e16e4164a36d8543b03c4184",
            "6c335de96a704479a919f922b8c13a61",
            "b23877477325495c86ff8b4164539146",
            "fd10ba66feb445718cfcc0fb9263c2de",
            "9de0c16624234114b06a7a144e927bd8",
            "64ce05e634c24cc182534d026e59b250",
            "5db8b3f7102f4484ab1b236bc590bd66",
            "f21514e184b8481a9421272545db0d92",
            "212f241c3d42454dada404f0f2085f4a",
            "fdb708f68edd4621829a1f715969a979",
            "4f443e78c5854868a7ff56ddeb1a7c32",
            "ca1fe2a8dcfe4d9ea17340a56b63472e",
            "341734b359734100ac0b2a5547b684ec",
            "c6540953d2b9448192746af30f09d55e",
            "a937812f8d3f4333804a9b3afb8e660a",
            "0a8ca797d91c46ce90e47c82391d6d37",
            "c42be7aca5244883bd3c5f277ab624fd",
            "c0fb859c834f4e9b872774b2f4a1fb43",
            "8b4388203a7842399a4ee2fdedc3256c",
            "db931c5377824f4cbfa451d850315de0",
            "36c2d6cab4cc4978a813185b220f23d7",
            "c1130345696c4ceba95a5e2974ceebce",
            "9c11e9696b6b41fe88b8ebd90a70ec8f",
            "6b274b808a9d47588fe9dd7443080d69",
            "61000c64e7f04e0b9792eca2192150d8",
            "fda67ad86bfc49919e0a5118e7d7934a",
            "d4bc782ea6124669824d3853a186c450",
            "4ed9606ef67f470b8ed598281131a5f7",
            "20af711caaf34760a4fce41e4ce55290",
            "b5c99f5c7a144454a224946e0f973e9e",
            "3f07792099b74e71b5099d7d7079ca6c",
            "4e6b952d00a947739f839767ef3d49f1",
            "e074e0105bbb4f10bdd6258ee54d81b3",
            "82b2f58bc7234f23a236a1873bc4f386",
            "d5c6d363d7134728bca49e61c6769b68",
            "7e990af441574e27979c7145effdb158",
            "163656db340a40feb77af8bca2e145ed",
            "1bb76ac0f09447849ee41ffd7d739900",
            "f67259fd527f4d49abe04cfed7ca6167",
            "fa938b49a6b043ee9b606a94556e71da",
            "d3519419ab8b42618ff9a7759d09001e",
            "7f7cba175ac34ec383d2c95da2252a6a",
            "4076abfebd194f2d8bc12b82d2365638",
            "f0b4ecc18dba4cf48074bc0062c295f5",
            "b993546fb9034ab4a72dae47a4d87045",
            "1e5fa75761db44009dcb9b48f2df3c1c",
            "9f74377b1c2245b6bb9ad4eb4a90512f",
            "aad3717fbaa84c45ad4091272d031438",
            "20db3980f5954f7eb2496b2ab67c7faf",
            "b290800a3227459e83078fba1a8ddc12",
            "5ecb35b31d6c4c428a0a23e769eb0895",
            "d82426f264f14712ac51c0e1bc572f78",
            "91f88220f3284e99815a81d705c4a7d7",
            "63c1f8aabae44776850d6bb86aa7b516"
          ]
        },
        "outputId": "7b1674e2-3e6b-4d5d-8f5b-d02759cdbfa4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a64f82db014a4369b67ba7ea9e87d892"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f95de66bd52b4fb980de0a6260af1d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8ca451f439f94b97a05ee10da51b5147"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4f443e78c5854868a7ff56ddeb1a7c32"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1130345696c4ceba95a5e2974ceebce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e074e0105bbb4f10bdd6258ee54d81b3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f0b4ecc18dba4cf48074bc0062c295f5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "User input: The movie was boring and too long\n",
            "Detected sentiment: negative\n",
            "\n",
            "Relevant context:\n",
            "The reviewer felt the movie was too long.\n",
            "The plot failed to keep the audience engaged.\n",
            "\n",
            "Generate a helpful and empathetic response.\n",
            "See also:\n"
          ]
        }
      ],
      "source": [
        "user_input = \"The movie was boring and too long\"\n",
        "\n",
        "sentiment = \"negative\"\n",
        "\n",
        "context = [\n",
        "    \"The reviewer felt the movie was too long.\",\n",
        "    \"The plot failed to keep the audience engaged.\"\n",
        "]\n",
        "\n",
        "prompt = build_prompt(user_input, context, sentiment)\n",
        "\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "gen_tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "gen_model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
        "\n",
        "inputs = gen_tokenizer(prompt, return_tensors=\"pt\")\n",
        "outputs = gen_model.generate(\n",
        "    **inputs,\n",
        "    max_length=200,\n",
        "    do_sample=True,\n",
        "    temperature=0.7,\n",
        "    top_p=0.9,\n",
        "    repetition_penalty=1.2,\n",
        "    no_repeat_ngram_size=3,\n",
        "    pad_token_id=gen_tokenizer.eos_token_id\n",
        ")\n",
        "\n",
        "response = gen_tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgHzhFoWXtES"
      },
      "source": [
        "# **Step 7:  Sentiment-Aware Assistant: Streamlit + ngrok**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok transformers torch\n",
        "\n",
        "app_code = r\"\"\"\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import time\n",
        "import os\n",
        "import csv\n",
        "\n",
        "# --- Простое retrieval ---\n",
        "CORPUS = [\n",
        "    \"The reviewer felt the movie was too long.\",\n",
        "    \"The plot failed to keep the audience engaged.\",\n",
        "    \"The characters felt flat and underdeveloped.\",\n",
        "    \"The cinematography was visually impressive.\"\n",
        "]\n",
        "\n",
        "def retrieve_context(text, k=2):\n",
        "    text = text.lower()\n",
        "    hits = [c for c in CORPUS if any(w in c.lower() for w in text.split())]\n",
        "    return hits[:k] if hits else CORPUS[:k]\n",
        "\n",
        "# --- Prompt builder (строгий, одна строка) ---\n",
        "def build_prompt(user_text, context):\n",
        "    return (\n",
        "        f\"Answer in 2–3 sentences using ONLY the information explicitly stated in the Context. \"\n",
        "        f\"Do NOT add new facts, opinions, examples, or references. \"\n",
        "        f\"If something is not mentioned in the Context, do not mention it. \"\n",
        "        f\"Context: {' '.join(context)} Review: {user_text}\"\n",
        "    )\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"distilgpt2\")\n",
        "\n",
        "def generate_response(prompt):\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "    outputs = model.generate(\n",
        "        **inputs,\n",
        "        max_new_tokens=80,\n",
        "        do_sample=True,\n",
        "        temperature=0.7,\n",
        "        top_p=0.9,\n",
        "        repetition_penalty=1.5,\n",
        "        no_repeat_ngram_size=3,\n",
        "        pad_token_id=tokenizer.eos_token_id\n",
        "    )\n",
        "    full_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    # Убираем prompt из вывода\n",
        "    response = full_text[len(prompt):].strip()\n",
        "    return response\n",
        "\n",
        "# --- Streamlit UI ---\n",
        "st.title(\"Sentiment-Aware Assistant\")\n",
        "\n",
        "user_text = st.text_area(\"Enter your text:\")\n",
        "\n",
        "if st.button(\"Analyze\"):\n",
        "    sentiment = \"Negative\" if any(w in user_text.lower() for w in [\"boring\", \"bad\", \"long\"]) else \"Positive\"\n",
        "    context = retrieve_context(user_text)\n",
        "    prompt = build_prompt(user_text, context)\n",
        "\n",
        "    start = time.time()\n",
        "    response = generate_response(prompt)\n",
        "    latency = time.time() - start\n",
        "\n",
        "    st.write(\"**Sentiment:**\", sentiment)\n",
        "    st.markdown(\"### 💬 Response\")\n",
        "    st.success(response)\n",
        "    st.write(f\"⏱ Response time: {latency:.2f} seconds\")\n",
        "\n",
        "    # --- Feedback ---\n",
        "    rating = st.slider(\"Rate the response\", 1, 5)\n",
        "    if st.button(\"Submit Feedback\"):\n",
        "        file_exists = os.path.isfile(\"feedback.csv\")\n",
        "        with open(\"feedback.csv\", \"a\", newline=\"\", encoding=\"utf-8\") as f:\n",
        "            writer = csv.writer(f)\n",
        "            if not file_exists:\n",
        "                writer.writerow([\"user_text\", \"response\", \"rating\"])\n",
        "            writer.writerow([user_text, response, rating])\n",
        "        st.success(\"Feedback submitted!\")\n",
        "\"\"\"\n",
        "\n",
        "with open(\"streamlit_app.py\", \"w\") as f:\n",
        "    f.write(app_code)\n",
        "\n",
        "import os, time\n",
        "os.system(\"nohup streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0 &\")\n",
        "time.sleep(5)\n",
        "\n",
        "from pyngrok import ngrok\n",
        "ngrok.set_auth_token(\"37mtMomlOJqFcTz3iY78fVrGh5m_5okvZPABVgnb3m2pDYDZW\")\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"Streamlit URL:\", public_url)\n"
      ],
      "metadata": {
        "id": "mw3E6R75xgmV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8becfa9b-6546-4a02-8979-cc56eee39dc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit URL: NgrokTunnel: \"https://melanospermous-quaternate-peg.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}